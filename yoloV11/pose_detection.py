from ultralytics import YOLO
import torch
import cv2
import numpy as np
import os
from pathlib import Path
import json
from datetime import datetime

# COCO Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Ï†ïÏùò
COCO_CLASSES = {
    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',
    6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant',
    11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat',
    16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant',
    21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella',
    26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis',
    31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove',
    36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass',
    41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',
    46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',
    51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake',
    56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table',
    61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote',
    66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster',
    71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase',
    76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'
}

def get_keypoint_name(idx):
    """ÌÇ§Ìè¨Ïù∏Ìä∏ Ïù∏Îç±Ïä§Ïóê Ìï¥ÎãπÌïòÎäî Ïù¥Î¶ÑÏùÑ Î∞òÌôò"""
    keypoint_names = {
        0: "ÏΩî", 1: "ÏôºÏ™Ω Îàà", 2: "Ïò§Î•∏Ï™Ω Îàà", 3: "ÏôºÏ™Ω Í∑Ä", 4: "Ïò§Î•∏Ï™Ω Í∑Ä",
        5: "ÏôºÏ™Ω Ïñ¥Íπ®", 6: "Ïò§Î•∏Ï™Ω Ïñ¥Íπ®", 7: "ÏôºÏ™Ω ÌåîÍøàÏπò", 8: "Ïò§Î•∏Ï™Ω ÌåîÍøàÏπò",
        9: "ÏôºÏ™Ω ÏÜêÎ™©", 10: "Ïò§Î•∏Ï™Ω ÏÜêÎ™©", 11: "ÏôºÏ™Ω ÏóâÎç©Ïù¥", 12: "Ïò§Î•∏Ï™Ω ÏóâÎç©Ïù¥",
        13: "ÏôºÏ™Ω Î¨¥Î¶é", 14: "Ïò§Î•∏Ï™Ω Î¨¥Î¶é", 15: "ÏôºÏ™Ω Î∞úÎ™©", 16: "Ïò§Î•∏Ï™Ω Î∞úÎ™©"
    }
    return keypoint_names.get(idx, f"ÌÇ§Ìè¨Ïù∏Ìä∏_{idx}")

def process_image(image_path, detect_model, pose_model, output_folder):
    """Îã®Ïùº Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨"""
    # Ïù¥ÎØ∏ÏßÄ Î°úÎìú
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"Error: Could not load image from {image_path}")
        return

    # ÌååÏùº Ïù¥Î¶Ñ Ï∂îÏ∂ú (ÌôïÏû•Ïûê Ï†úÏô∏)
    image_name = Path(image_path).stem

    # Î¨ºÏ≤¥ Ïù∏Ïãù ÔøΩÔøΩÔøΩ Ìè¨Ï¶à Ï∂îÏ†ï Ïã§Ìñâ
    detect_results = detect_model(image)
    pose_results = pose_model(image)

    # Í≤∞Í≥º Ï∂úÎ†•
    print(f"\n=== {image_name} Î∂ÑÏÑù Í≤∞Í≥º ===")
    
    # Î¨ºÏ≤¥ Ïù∏Ïãù Í≤∞Í≥º
    print("\nÎ¨ºÏ≤¥ Ïù∏Ïãù Í≤∞Í≥º:")
    for result in detect_results:
        boxes = result.boxes
        if len(boxes) > 0:
            for box in boxes:
                cls = int(box.cls[0])
                cls_name = COCO_CLASSES.get(cls, f"class_{cls}")
                conf = float(box.conf[0])
                coords = box.xyxy[0].cpu().numpy()
                print(f"ÌÅ¥ÎûòÏä§: {cls_name}, Ïã†Î¢∞ÎèÑ: {conf:.2f}")
                print(f"Î∞ïÏä§ Ï¢åÌëú: {coords}")

    # JSONÏúºÎ°ú Ï†ÄÏû•Ìï† Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ ÏÉùÏÑ±
    pose_data = {
        "timestamp": datetime.now().isoformat(),
        "image_name": image_name,
        "people": []
    }

    # Ìè¨Ï¶à Ï∂îÏ†ï Í≤∞Í≥º
    print("\nÌè¨Ï¶à Ï∂îÏ†ï Í≤∞Í≥º:")
    for result in pose_results:
        keypoints = result.keypoints
        if keypoints is not None:
            keypoints_data = keypoints.data.cpu().numpy()
            for person_idx, person_keypoints in enumerate(keypoints_data):
                person_data = {
                    "person_id": person_idx,
                    "keypoints": []
                }
                print(f"\nÏÇ¨Îûå {person_idx + 1}Ïùò ÌÇ§Ìè¨Ïù∏Ìä∏:")
                for kp_idx, kp in enumerate(person_keypoints):
                    x, y, conf = kp
                    kp_name = get_keypoint_name(kp_idx)
                    print(f"{kp_name}: x={x:.2f}, y={y:.2f}, confidence={conf:.2f}")
                    
                    # JSON Îç∞Ïù¥ÌÑ∞Ïóê ÌÇ§Ìè¨Ïù∏Ìä∏ Ï∂îÍ∞Ä
                    person_data["keypoints"].append({
                        "name": kp_name,
                        "id": kp_idx,
                        "coordinates": {
                            "x": float(x),
                            "y": float(y)
                        },
                        "confidence": float(conf)
                    })
                pose_data["people"].append(person_data)

    # JSON ÌååÏùºÎ°ú Ï†ÄÏû•
    json_output_path = os.path.join(output_folder, f'{image_name}_pose.json')
    with open(json_output_path, 'w', encoding='utf-8') as f:
        json.dump(pose_data, f, ensure_ascii=False, indent=2)
    print(f"Ìè¨Ï¶à Îç∞Ïù¥ÌÑ∞ JSON Ï†ÄÏû•Îê®: {json_output_path}")

    # Í≤∞Í≥º ÏãúÍ∞ÅÌôî
    img = image.copy()
    
    # Î¨ºÏ≤¥ Ïù∏Ïãù Í≤∞Í≥º Í∑∏Î¶¨Í∏∞
    for result in detect_results:
        boxes = result.boxes
        for box in boxes:
            coords = box.xyxy[0].cpu().numpy().astype(int)
            cls = int(box.cls[0])
            cls_name = COCO_CLASSES.get(cls, f"class_{cls}")
            conf = float(box.conf[0])
            
            cv2.rectangle(img, (coords[0], coords[1]), (coords[2], coords[3]), (0, 255, 0), 2)
            cv2.putText(img, f"{cls_name} {conf:.2f}", (coords[0], coords[1]-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Ìè¨Ï¶à Ï∂îÏ†ï Í≤∞Í≥º Í∑∏Î¶¨Í∏∞
    for result in pose_results:
        keypoints = result.keypoints
        if keypoints is not None:
            keypoints_data = keypoints.data.cpu().numpy()
            for person_keypoints in keypoints_data:
                # ÌÇ§Ìè¨Ïù∏Ìä∏ Í∑∏Î¶¨Í∏∞
                for x, y, conf in person_keypoints:
                    if conf > 0.5:  # Ïã†Î¢∞ÎèÑÍ∞Ä ÎÜíÏùÄ ÌÇ§Ìè¨Ïù∏Ìä∏Îßå ÌëúÏãú
                        cv2.circle(img, (int(x), int(y)), 3, (0, 0, 255), -1)

    # Í≤∞Í≥º Ï†ÄÏû•
    output_path = os.path.join(output_folder, f'{image_name}_result.jpg')
    cv2.imwrite(output_path, img)
    print(f"Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•Îê®: {output_path}")

def initialize_models():
    """Î™®Îç∏ Ï¥àÍ∏∞Ìôî"""
    detect_model = YOLO('inference/yolo11l.pt')
    pose_model = YOLO('inference/yolo11l-pose.pt')
    return detect_model, pose_model

def process_realtime(frame, detect_model, pose_model):
    with torch.cuda.amp.autocast():
        with torch.inference_mode():
            # YOLO Ï≤òÎ¶¨
            detect_results = detect_model(frame, conf=0.5)  # Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï
            pose_results = pose_model(frame, conf=0.5)
            
            # Í≤∞Í≥º Ï≤òÎ¶¨
            results = {
                'objects': [],
                'poses': []
            }
            
            # Í∞ùÏ≤¥ Í∞êÏßÄ Í≤∞Í≥º Ï≤òÎ¶¨
            for result in detect_results:
                boxes = result.boxes
                for box in boxes:
                    cls = int(box.cls[0])
                    cls_name = COCO_CLASSES.get(cls, f"class_{cls}")
                    conf = float(box.conf[0])
                    coords = box.xyxy[0].cpu().numpy()
                    
                    results['objects'].append({
                        'class': cls_name,
                        'confidence': conf,
                        'bbox': coords.tolist()
                    })
            
            # Ìè¨Ï¶à Ï∂îÏ†ï Í≤∞Í≥º Ï≤òÎ¶¨
            for result in pose_results:
                keypoints = result.keypoints
                if keypoints is not None:
                    keypoints_data = keypoints.data.cpu().numpy()
                    for person_idx, person_keypoints in enumerate(keypoints_data):
                        person_data = {
                            'person_id': person_idx,
                            'keypoints': []
                        }
                        
                        for kp_idx, kp in enumerate(person_keypoints):
                            x, y, conf = kp
                            kp_name = get_keypoint_name(kp_idx)
                            person_data['keypoints'].append({
                                'name': kp_name,
                                'coordinates': {
                                    'x': float(x),
                                    'y': float(y)
                                },
                                'confidence': float(conf)
                            })
                        results['poses'].append(person_data)
            
            return results

def process_single_person_with_objects(image, detect_model, pose_model):
    """
    Ïù¥ÎØ∏ÏßÄÏóêÏÑú Í∞ÄÏû• ÌÅ∞ ÏÇ¨ÎûåÏùò Ïä§ÏºàÎ†àÌÜ§ Îç∞Ïù¥ÌÑ∞Î•º ÏöîÏ≤≠ÌïòÏã† Íµ¨Ï°∞Î°ú Î∞òÌôòÌïòÍ≥†, Í∞ùÏ≤¥ Îç∞Ïù¥ÌÑ∞Î•º Ìï®Íªò Î∞òÌôò.
    """
    with torch.cuda.amp.autocast():
        with torch.inference_mode():
            # YOLO Ï≤òÎ¶¨
            detect_results = detect_model(image, conf=0.5)  # Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï
            pose_results = pose_model(image, conf=0.5)
            
            # Í≤∞Í≥º Ï†ÄÏû•ÏùÑ ÏúÑÌïú Íµ¨Ï°∞
            skeleton_data = {
                "keypoints": {},
                "confidence_scores": {}
            }
            object_data = []

            # Í∞ùÏ≤¥ Í∞êÏßÄ Í≤∞Í≥º Ï≤òÎ¶¨
            for result in detect_results:
                boxes = result.boxes
                for box in boxes:
                    cls = int(box.cls[0])
                    cls_name = COCO_CLASSES.get(cls, f"class_{cls}")
                    conf = float(box.conf[0])
                    coords = box.xyxy[0].cpu().numpy()

                    object_data.append({
                        'class': cls_name,
                        'confidence': conf,
                        'bbox': coords.tolist()
                    })

            # Ìè¨Ï¶à Ï∂îÏ†ï Í≤∞Í≥º Ï≤òÎ¶¨
            largest_area = 0  # Í∞ÄÏû• ÌÅ∞ ÏÇ¨ÎûåÏùÑ Ï∞æÍ∏∞ ÏúÑÌïú Í∏∞Ï§Ä
            keypoint_names = [
                "nose", "left_eye", "right_eye", "left_ear", "right_ear",
                "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
                "left_wrist", "right_wrist", "left_hip", "right_hip",
                "left_knee", "right_knee", "left_ankle", "right_ankle"
            ]

            for result in pose_results:
                keypoints = result.keypoints
                if keypoints is not None:
                    keypoints_data = keypoints.data.cpu().numpy()
                    for person_keypoints in keypoints_data:
                        # x, y Ï¢åÌëúÎßå Ï∂îÏ∂ú
                        x_coords = person_keypoints[:, 0]
                        y_coords = person_keypoints[:, 1]

                        # Îπà Î∞∞Ïó¥ Î∞©ÏßÄ
                        if x_coords.size == 0 or y_coords.size == 0:
                            continue  # Îã§Ïùå ÏÇ¨ÎûåÏúºÎ°ú ÎÑòÏñ¥Í∞ê

                        # ÌÇ§Ìè¨Ïù∏Ìä∏Î•º Í∏∞Ï§ÄÏúºÎ°ú ÌÅ¨Í∏∞ Í≥ÑÏÇ∞
                        x_min, x_max = x_coords.min(), x_coords.max()
                        y_min, y_max = y_coords.min(), y_coords.max()
                        area = (x_max - x_min) * (y_max - y_min)

                        # Í∞ÄÏû• ÌÅ∞ ÏÇ¨Îûå Ï∞æÍ∏∞
                        if area > largest_area:
                            largest_area = area
                            skeleton_data = {  # Íµ¨Ï°∞ ÏÉùÏÑ±
                                "keypoints": {},
                                "confidence_scores": {}
                            }
                            for idx, (x, y, conf) in enumerate(person_keypoints):
                                if idx < len(keypoint_names):  # ÌÇ§Ìè¨Ïù∏Ìä∏ Ïù¥Î¶ÑÏù¥ ÏûàÎäî Í≤ΩÏö∞Îßå Ï≤òÎ¶¨
                                    keypoint_name = keypoint_names[idx]
                                    skeleton_data["keypoints"][keypoint_name] = {
                                        "x": float(x),
                                        "y": float(y),
                                        "z": 0  # 2D Ïù¥ÎØ∏ÏßÄÏù¥ÎØÄÎ°ú zÎäî 0ÏúºÎ°ú ÏÑ§Ï†ï
                                    }
                                    skeleton_data["confidence_scores"][keypoint_name] = float(conf)

    return skeleton_data, object_data



def main():
    # GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏
    if torch.cuda.is_available():
        print("CUDA is available! üöÄ")
        print(f"Device name: {torch.cuda.get_device_name(0)}")
        print(f"Number of GPUs: {torch.cuda.device_count()}")
    else:
        print("CUDA is not available. Running on CPU.")

    # Î™®Îç∏ Î°úÎìú
    detect_model = YOLO('inference/yolo11l.pt')
    pose_model = YOLO('inference/yolo11l-pose.pt')

    # ÏûÖÎ†•/Ï∂úÎ†• Ìè¥Îçî ÏÑ§Ï†ï
    input_folder = 'img'
    output_folder = 'outputs'
    os.makedirs(output_folder, exist_ok=True)

    # ÏßÄÏõêÌïòÎäî Ïù¥ÎØ∏ÏßÄ ÌôïÏû•Ïûê
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

    # ÏûÖÎ†• Ìè¥ÎçîÏùò Î™®Îì† Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨
    image_files = [f for f in Path(input_folder).glob('*') if f.suffix.lower() in image_extensions]
    
    if not image_files:
        print(f"Error: No image files found in {input_folder}")
        return

    print(f"\nÏ¥ù {len(image_files)}Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ•º Ï≤òÎ¶¨Ìï©ÎãàÎã§.")
    
    # Í∞Å Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨
    for image_path in image_files:
        try:
            process_image(image_path, detect_model, pose_model, output_folder)
        except Exception as e:
            print(f"Error processing {image_path}: {str(e)}")

    print("\nÎ™®Îì† Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨Í∞Ä ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.")
# alex ÏàòÏ†ï test1
# alex ÏàòÏ†ï test2
# alex ÏàòÏ†ï test3

if __name__ == "__main__":
    main()